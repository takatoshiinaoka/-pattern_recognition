{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "パターン認識4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbLtjZO7ViJ0EaWHSzx6XX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatoshiinaoka/-pattern_recognition/blob/main/%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%984.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# パターン認識\n",
        "## 第4回：パターン認識(3章後半)\n"
      ],
      "metadata": {
        "id": "9ZNbIvz_0hLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 各層における伝達信号の実装"
      ],
      "metadata": {
        "id": "Ayj5sGRo29Jt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvtlQTuz0gV6",
        "outputId": "4a279c4e-77a9-428d-cb4f-807b2735dec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n",
            "(2, 3)\n",
            "(3, 2)\n",
            "(2, 2)\n",
            "(3,)\n",
            "(2,)\n",
            "(2,)\n",
            "\n",
            "[0.3 0.7 1.1]\n",
            "[0.57444252 0.66818777 0.75026011]\n",
            "\n",
            "[0.51615984 1.21402696]\n",
            "[0.62624937 0.7710107 ]\n",
            "\n",
            "[0.31682708 0.69627909]\n",
            "[0.31682708 0.69627909]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "X = np.array([1.0, 0.5])\n",
        "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "B1 = np.array([0.1, 0.2, 0.3])\n",
        "B2 = np.array([0.1, 0.2])\n",
        "B3 = np.array([0.1, 0.2])\n",
        "\n",
        "print(X.shape)\n",
        "print(W1.shape)\n",
        "print(W2.shape)\n",
        "print(W3.shape)\n",
        "print(B1.shape)\n",
        "print(B2.shape)\n",
        "print(B3.shape)\n",
        "print()\n",
        "\n",
        "#シグモイド関数\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "#恒等関数\n",
        "def identity_function(x): \n",
        "  return x  #今回は何の計算もしていない[目的によって変わる]\n",
        "\n",
        "#1層目の計算\n",
        "A1 = np.dot(X, W1) + B1\n",
        "Z1 = sigmoid(A1) \n",
        "print(str(A1) +\"\\n\"+ str(Z1), end=\"\\n\\n\")\n",
        "\n",
        "#2層目の計算\n",
        "A2 = np.dot(Z1, W2) + B2\n",
        "Z2 = sigmoid(A2) \n",
        "print(str(A2) +\"\\n\"+ str(Z2), end=\"\\n\\n\")\n",
        "\n",
        "#3層目の計算\n",
        "A3 = np.dot(Z2, W3) + B3\n",
        "Y = identity_function(A3) \n",
        "print(str(A3) +\"\\n\"+ str(Y), end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実装まとめ"
      ],
      "metadata": {
        "id": "R0uCkS_V7hNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def identity_function(x): \n",
        "  return x  \n",
        "\n",
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a/sum_exp_a\n",
        "  return y\n",
        "\n",
        "def init_network(): #重みとバイアスの初期化\n",
        "  network = {} \n",
        "  network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "  network['b1'] = np.array([0.1, 0.2, 0.3])\n",
        "  network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "  network['b2'] = np.array([0.1, 0.2])\n",
        "  network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "  network['b3'] = np.array([0.1, 0.2])\n",
        "\n",
        "  return network\n",
        "  \n",
        "def forwarod(network, x): #前向きの伝達情報. 後ろで,後ろ向きの学習がある.\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1) \n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  z2 = sigmoid(a2) \n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y = identity_function(a3) \n",
        "\n",
        "  return y\n",
        "\n",
        "network = init_network()\n",
        "x = np.array([1.0, 0.5])   #入力でーた\n",
        "y = forwarod(network, x)  #出力データ\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B28HM-in3obu",
        "outputId": "1fd9f8ca-6cd2-4885-882c-1a6c38919c59"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31682708 0.69627909]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 出力層の設計\n",
        "- 分類問題\n",
        "  - データがどのクラスに属するか  \n",
        "  例：写真の人物は男か？女か？\n",
        "  - 活性化関数としてソフトマックス関数を使う　　\n",
        "\n",
        "  ```\n",
        "  def softmax(a):\n",
        "    exp_a = np.exp(a)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a/sum_exp_a\n",
        "    return y\n",
        "  ```\n",
        "- 回帰問題\n",
        "  - データから,別の数値を予想  \n",
        "  例：写真の人物の体重は？\n",
        "  - 活性化関数として恒等関数を使う  \n",
        "  \n",
        "  ```\n",
        "  def identity_function(x): \n",
        "    return x  \n",
        "  ```"
      ],
      "metadata": {
        "id": "WkzMuDbyGST2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a/sum_exp_a\n",
        "  return y\n",
        "\n",
        "a = np.array([0.3, 2.9, 4.0])\n",
        "softmax(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwwWrTe7i7d",
        "outputId": "2bfb9cbf-2f9b-4cf8-a959-ac5168ed5b75"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01821127, 0.24519181, 0.73659691])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ソフトマックス関数の特徴\n",
        "- オーバーフローに注意"
      ],
      "metadata": {
        "id": "_qURnbmqLy6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a - c)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a/sum_exp_a\n",
        "  return y\n",
        "\n",
        "a = np.array([0.3, 2.9, 4.0])\n",
        "softmax(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d7NYFNMI8mW",
        "outputId": "6a551397-21b0-4859-b187-08e50aab3296"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01821127, 0.24519181, 0.73659691])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 出力層ニューロンの数\n",
        "- 解くべき問題に応じて決める\n",
        "- 例：手書きの数字を認識する\n",
        "  - 数字は0~9の10個 = 10クラス\n",
        "\n",
        "### 手書き数字認識\n",
        "- 手書き数字画像を分類する  \n",
        "ニューラルネットを作る\n",
        "- 重みなどのパラメータは？\n",
        "  - 実際は学習で求める\n",
        "  - 今回は学習済みのパラメータを使用\n",
        "- 認識処理(推論処理)はニューラルネットの順方向伝播  \n",
        "forward propagation\n"
      ],
      "metadata": {
        "id": "35SuvAPmMCpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNISTデータセット\n",
        "- 手書き数字の有名なデータセット\n",
        "- 0~9の数字画像\n",
        "  - 訓練用画像：60,000枚\n",
        "  - テスト用画像：10,000枚\n",
        "  - 28×28ピクセルのグレー画像\n",
        "  - 各ビクセルは0~255の値"
      ],
      "metadata": {
        "id": "T96KKjpFNLJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ニューラルネットワークの推論処理\n",
        "- ニューラルネットの構成\n",
        "  - 入力層：784ニューロン(28×28ピクセル)\n",
        "  - 出力層：10ニューロン(0~9の10クラス)\n",
        "  - 隠れ層：経験から決める(変更可)\n",
        "    - 1つ目：50ニューロン \n",
        "    - 2つ目：100ニューロン"
      ],
      "metadata": {
        "id": "_7vFrjydNp5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist_show.py\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from PIL import Image\n",
        "\n",
        "def img_show(img):\n",
        "  pil_img = Image.fromarray(np.uint8(img))\n",
        "  pil_img.show()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_tarain[0]\n",
        "print(label) #5\n",
        "\n",
        "print(img.shape) #(784,)\n",
        "img = img.reshape(28, 28) #形状を元の画像サイズに変換\n",
        "print(img.shape)\n",
        "\n",
        "img.show()\n"
      ],
      "metadata": {
        "id": "1wKoWfyTOvQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#neuralnet_mnist.py\n",
        "import sys, os\n",
        "sys.path.append(os.pardir) #親ディレクトファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import pickle\n",
        "from dataset.mnist import load_mnist\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "\n",
        "def get_data():\n",
        "  (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "  return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "  with open(\"sample_weight.pkl\", 'rb') as f:\n",
        "    network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "def predict(network, x):\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1) \n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  z2 = sigmoid(a2) \n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y = softmax(a3) \n",
        "\n",
        "  return y\n",
        "\n",
        "  x, t = get_data()\n",
        "  network = init_network()\n",
        "\n",
        "  accuracy_cnt = 0\n",
        "  for i in range(len(x)):  \n",
        "    y = predict(network, x[i])\n",
        "    p = np.argmax(y)  #最も確率の高い要素のインデックスを取得\n",
        "    if p == t[i]:\n",
        "      accuracy_cnt += 1 #正解数をカウント\n",
        "\n",
        "  print(\"Accuracy：\" + str(float(accuracy_cnt)/len(x)))\n"
      ],
      "metadata": {
        "id": "xhhhN9LXR4Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### バッチ処理\n",
        "- 1枚の画像(28×28=784ピクセル)からどの数字か認識\n",
        "\n",
        "\n",
        "|  x | w1 | w2 | w3 | Y |\n",
        "| ---- | ---- | ---- | ---- | ---- |\n",
        "| 784 | 784*50 | 50*100 | 100*10 | 10 |\n",
        "\n",
        "\n",
        "- 100枚の画像の写真からそれぞれどの数字か認識\n",
        "\n",
        "\n",
        "|  x | w1 | w2 | w3 | Y |\n",
        "| ---- | ---- | ---- | ---- | ---- |\n",
        "| 100*784 | 784*50 | 50*100 | 100*10 | 10 |\n"
      ],
      "metadata": {
        "id": "80QC8cxfTOlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100 #バッチの数\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "  x_batch = x[i : i+batch_size] #入力データを100枚づつまとめる\n",
        "  y_batch = predict(network, x_batch)\n",
        "  p = np.argmax(y_batch, axis=1)\n",
        "  accuracy_cnt += np.sum(p == t[i:i+batch_size]) #正しい答えの数をカウント\n",
        "\n",
        "print(\"Accuracy：\" + str(float(accuracy_cnt)/len(x)))"
      ],
      "metadata": {
        "id": "vw7KJ5oWUIwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LLWwujpHVRyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}